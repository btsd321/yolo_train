# YOLO segmentå¯è§†åŒ–å·¥å…·
# åŠŸèƒ½ï¼šå¯è§†åŒ–YOLOåˆ†å‰²æ ¼å¼çš„æ ‡æ³¨æ–‡ä»¶
# è¾“å…¥ï¼šåŒ…å«å›¾ç‰‡å’Œtxtåˆ†å‰²æ ‡æ³¨æ–‡ä»¶çš„æ–‡ä»¶å¤¹
# æ˜¾ç¤ºï¼šåŠé€æ˜æ©ç  + è¾¹ç•Œçº¿æ¡ + ç±»åˆ«æ ‡ç­¾

import cv2
import os
import argparse
from pathlib import Path
import numpy as np


# æ¯ä¸ªç±»åˆ«å¯¹åº”çš„é¢œè‰²ï¼ˆBGRæ ¼å¼ï¼‰- 20ç§é¢œè‰²
CLASS_COLORS = {
    0: (0, 255, 0),       # ç»¿è‰²
    1: (255, 0, 0),       # è“è‰²
    2: (0, 0, 255),       # çº¢è‰²
    3: (255, 255, 0),     # é’è‰²
    4: (255, 0, 255),     # æ´‹çº¢
    5: (0, 255, 255),     # é»„è‰²
    6: (0, 165, 255),     # æ©™è‰²
    7: (128, 0, 128),     # ç´«è‰²
    8: (203, 192, 255),   # ç²‰çº¢
    9: (42, 42, 165),     # æ£•è‰²
    10: (0, 128, 0),      # æ·±ç»¿
    11: (139, 0, 0),      # æ·±è“
    12: (0, 0, 139),      # æ·±çº¢
    13: (255, 191, 0),    # å¤©è“
    14: (0, 255, 191),    # çŸ³ç°ç»¿
    15: (80, 127, 255),   # çŠç‘šè‰²
    16: (0, 215, 255),    # é‡‘è‰²
    17: (139, 139, 0),    # æ·±é’
    18: (139, 0, 139),    # æ·±æ´‹çº¢
    19: (0, 140, 255)     # æ·±æ©™
}

# ç”¨äºè·Ÿè¸ªå·²è­¦å‘Šçš„ç±»åˆ«ID
_warned_class_ids = set()


def load_class_names(names_file_path):
    """
    ä»txtæ–‡ä»¶åŠ è½½ç±»åˆ«åç§°
    æ ¼å¼: æ¯è¡Œä¸º "id name"
    è¿”å›: {class_id: class_name, ...}
    """
    class_names = {}
    
    if not names_file_path or not os.path.exists(names_file_path):
        return class_names
    
    try:
        with open(names_file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith('#'):
                    continue
                
                parts = line.split(maxsplit=1)
                if len(parts) == 2:
                    class_id = int(parts[0])
                    class_name = parts[1]
                    class_names[class_id] = class_name
        
        print(f"æˆåŠŸåŠ è½½ {len(class_names)} ä¸ªç±»åˆ«åç§°")
    except Exception as e:
        print(f"è­¦å‘Š: åŠ è½½ç±»åˆ«åç§°æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    return class_names


def parse_yolo_segment(txt_file_path):
    """
    è§£æYOLOåˆ†å‰²æ ¼å¼çš„æ ‡æ³¨æ–‡ä»¶
    æ ¼å¼: class_id x1 y1 x2 y2 x3 y3 ... xn yn (å½’ä¸€åŒ–åæ ‡)
    è¿”å›: [(class_id, [(x1,y1), (x2,y2), ...]), ...]
    """
    annotations = []
    
    if not os.path.exists(txt_file_path):
        return annotations
    
    with open(txt_file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        parts = line.split()
        if len(parts) >= 7:  # è‡³å°‘éœ€è¦class_id + 3ä¸ªç‚¹(6ä¸ªåæ ‡)
            class_id = int(parts[0])
            
            # è§£æå¤šè¾¹å½¢ç‚¹åæ ‡
            coords = [float(x) for x in parts[1:]]
            
            # ç¡®ä¿åæ ‡æ•°é‡æ˜¯å¶æ•°ï¼ˆx,yå¯¹ï¼‰
            if len(coords) % 2 != 0:
                print(f"è­¦å‘Š: è·³è¿‡æ— æ•ˆçš„åæ ‡æ•°æ®ï¼ˆåæ ‡æ•°é‡ä¸æ˜¯å¶æ•°ï¼‰")
                continue
            
            # å°†åæ ‡è½¬æ¢ä¸ºç‚¹åˆ—è¡¨
            points = []
            for i in range(0, len(coords), 2):
                points.append((coords[i], coords[i+1]))
            
            annotations.append((class_id, points))
    
    return annotations


def draw_yolo_segment(image, annotations, class_names=None, alpha=0.4):
    """
    åœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶YOLOåˆ†å‰²æ ¼å¼çš„æ©ç 
    å‚æ•°:
        image: è¾“å…¥å›¾åƒ
        annotations: [(class_id, [(x1,y1), (x2,y2), ...]), ...]
        class_names: ç±»åˆ«åç§°å­—å…¸ {class_id: class_name}
        alpha: æ©ç é€æ˜åº¦ (0.0-1.0)
    """
    img_height, img_width = image.shape[:2]
    
    # æ ¹æ®å›¾åƒåˆ†è¾¨ç‡è‡ªé€‚åº”è°ƒæ•´å‚æ•°
    base_size = 1920
    scale_factor = min(img_width, img_height) / base_size
    
    # è‡ªé€‚åº”çº¿æ¡ç²—ç»†
    line_thickness = max(1, min(8, int(2 * scale_factor)))
    
    # è‡ªé€‚åº”å­—ä½“å‚æ•°
    font_scale = max(0.3, min(2.0, 0.6 * scale_factor))
    font_thickness = max(1, min(5, int(2 * scale_factor)))
    padding = max(2, int(5 * scale_factor))
    
    # åˆ›å»ºä¸€ä¸ªoverlayå›¾å±‚ç”¨äºç»˜åˆ¶åŠé€æ˜æ©ç 
    overlay = image.copy()
    
    for class_id, points in annotations:
        # å°†å½’ä¸€åŒ–åæ ‡è½¬æ¢ä¸ºåƒç´ åæ ‡
        pixel_points = []
        for x, y in points:
            px = int(x * img_width)
            py = int(y * img_height)
            pixel_points.append([px, py])
        
        pixel_points = np.array(pixel_points, dtype=np.int32)
        
        # è·å–é¢œè‰²ï¼ˆæ”¯æŒè¶…è¿‡20ä¸ªç±»åˆ«ï¼‰
        if class_id >= 20:
            if class_id not in _warned_class_ids:
                print(f"âš  è­¦å‘Š: ç±»åˆ«ID {class_id} è¶…è¿‡20ï¼Œå°†å¾ªç¯ä½¿ç”¨é¢œè‰²ï¼ˆä½¿ç”¨é¢œè‰²ç´¢å¼• {class_id % 20}ï¼‰")
                _warned_class_ids.add(class_id)
            color = CLASS_COLORS.get(class_id % 20, (0, 255, 255))
        else:
            color = CLASS_COLORS.get(class_id, (0, 255, 255))
        
        # ç»˜åˆ¶å¡«å……çš„å¤šè¾¹å½¢ï¼ˆåŠé€æ˜æ©ç ï¼‰
        cv2.fillPoly(overlay, [pixel_points], color)
        
        # ç»˜åˆ¶å¤šè¾¹å½¢è¾¹ç•Œï¼ˆå®çº¿ï¼‰
        cv2.polylines(image, [pixel_points], isClosed=True, color=color, thickness=line_thickness)
        
        # è®¡ç®—å¤šè¾¹å½¢çš„ä¸­å¿ƒç‚¹æˆ–è¾¹ç•Œæ¡†æ¥æ”¾ç½®æ ‡ç­¾
        x_coords = [p[0] for p in pixel_points]
        y_coords = [p[1] for p in pixel_points]
        x_min, x_max = min(x_coords), max(x_coords)
        y_min, y_max = min(y_coords), max(y_coords)
        
        # æ ‡ç­¾æ”¾åœ¨è¾¹ç•Œæ¡†å·¦ä¸Šè§’
        label_x = x_min
        label_y = y_min
        
        # è·å–ç±»åˆ«åç§°
        if class_names and class_id in class_names:
            class_name = class_names[class_id]
            label = f'{class_name} (ID:{class_id})'
        else:
            label = f'ID:{class_id}'
        
        # è®¡ç®—æ–‡æœ¬å¤§å°
        font = cv2.FONT_HERSHEY_SIMPLEX
        (text_width, text_height), baseline = cv2.getTextSize(
            label, font, font_scale, font_thickness
        )
        
        # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
        cv2.rectangle(
            image,
            (label_x, label_y - text_height - baseline - padding),
            (label_x + text_width + padding, label_y),
            color,
            -1
        )
        
        # ç»˜åˆ¶æ ‡ç­¾æ–‡æœ¬
        cv2.putText(
            image,
            label,
            (label_x + padding // 2, label_y - baseline - padding // 2),
            font,
            font_scale,
            (255, 255, 255),
            font_thickness
        )
    
    # å°†overlayä¸åŸå›¾æ··åˆï¼Œå®ç°åŠé€æ˜æ•ˆæœ
    cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0, image)
    
    return image


print("âœ“ æ­¥éª¤2å®Œæˆ: åŠé€æ˜æ©ç ç»˜åˆ¶å‡½æ•°")
print("å·²æœ‰çŸ¥è¯†:")
print("  - draw_yolo_segment(): ç»˜åˆ¶åˆ†å‰²æ©ç ")
print("    Â· ä½¿ç”¨cv2.fillPoly()å¡«å……å¤šè¾¹å½¢")
print("    Â· ä½¿ç”¨cv2.polylines()ç»˜åˆ¶è¾¹ç•Œ")
print("    Â· ä½¿ç”¨cv2.addWeighted()å®ç°åŠé€æ˜æ•ˆæœ")
print("    Â· alphaå‚æ•°æ§åˆ¶é€æ˜åº¦(é»˜è®¤0.4)")
print("    Â· è‡ªé€‚åº”çº¿æ¡ç²—ç»†å’Œå­—ä½“å¤§å°")


def find_image_annotation_pairs(folder_path):
    """
    æŸ¥æ‰¾æ–‡ä»¶å¤¹ä¸­æˆå¯¹çš„å›¾ç‰‡å’Œæ ‡æ³¨æ–‡ä»¶
    è¿”å›: [(image_path, txt_path), ...]
    """
    folder = Path(folder_path)
    if not folder.exists():
        print(f"é”™è¯¯: æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}")
        return []
    
    # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}
    
    pairs = []
    seen_files = set()  # ç”¨äºå»é‡
    
    # éå†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶
    for file_path in folder.iterdir():
        if not file_path.is_file():
            continue
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å›¾ç‰‡æ–‡ä»¶ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
        if file_path.suffix.lower() in image_extensions:
            # æŸ¥æ‰¾å¯¹åº”çš„txtæ–‡ä»¶
            txt_file = file_path.with_suffix('.txt')
            if txt_file.exists():
                # ä½¿ç”¨æ–‡ä»¶çš„stemï¼ˆä¸å«æ‰©å±•åçš„æ–‡ä»¶åï¼‰ä½œä¸ºå”¯ä¸€æ ‡è¯†
                file_stem = file_path.stem.lower()
                if file_stem not in seen_files:
                    seen_files.add(file_stem)
                    pairs.append((str(file_path), str(txt_file)))
    
    # æŒ‰æ–‡ä»¶åæ’åº
    pairs.sort(key=lambda x: x[0])
    
    return pairs


class ImageViewer:
    """æ”¯æŒé¼ æ ‡ç¼©æ”¾å’Œæ‹–æ‹½çš„å›¾åƒæŸ¥çœ‹å™¨"""
    def __init__(self, window_name):
        self.window_name = window_name
        self.zoom_scale = 1.0
        self.offset_x = 0
        self.offset_y = 0
        self.dragging = False
        self.last_x = 0
        self.last_y = 0
        self.original_image = None
        self.display_image = None
        
    def mouse_callback(self, event, x, y, flags, param):
        """é¼ æ ‡äº‹ä»¶å›è°ƒå‡½æ•°"""
        if event == cv2.EVENT_MOUSEWHEEL:
            # é¼ æ ‡æ»šè½®ç¼©æ”¾
            if flags > 0:  # å‘ä¸Šæ»šåŠ¨ï¼Œæ”¾å¤§
                self.zoom_scale *= 1.1
            else:  # å‘ä¸‹æ»šåŠ¨ï¼Œç¼©å°
                self.zoom_scale *= 0.9
            
            # é™åˆ¶ç¼©æ”¾èŒƒå›´
            self.zoom_scale = max(0.1, min(10.0, self.zoom_scale))
            self.update_display()
            
        elif event == cv2.EVENT_LBUTTONDOWN:
            # å¼€å§‹æ‹–æ‹½
            self.dragging = True
            self.last_x = x
            self.last_y = y
            
        elif event == cv2.EVENT_LBUTTONUP:
            # ç»“æŸæ‹–æ‹½
            self.dragging = False
            
        elif event == cv2.EVENT_MOUSEMOVE:
            # æ‹–æ‹½ç§»åŠ¨
            if self.dragging:
                dx = x - self.last_x
                dy = y - self.last_y
                self.offset_x += dx
                self.offset_y += dy
                self.last_x = x
                self.last_y = y
                self.update_display()
    
    def set_image(self, image):
        """è®¾ç½®è¦æ˜¾ç¤ºçš„å›¾åƒ"""
        self.original_image = image.copy()
        self.zoom_scale = 1.0
        self.offset_x = 0
        self.offset_y = 0
        self.update_display()
    
    def update_display(self):
        """æ›´æ–°æ˜¾ç¤ºçš„å›¾åƒ"""
        if self.original_image is None:
            return
        
        # åº”ç”¨ç¼©æ”¾
        if self.zoom_scale != 1.0:
            new_width = int(self.original_image.shape[1] * self.zoom_scale)
            new_height = int(self.original_image.shape[0] * self.zoom_scale)
            scaled_image = cv2.resize(self.original_image, (new_width, new_height))
        else:
            scaled_image = self.original_image.copy()
        
        # åˆ›å»ºæ˜¾ç¤ºç”»å¸ƒï¼ˆä¿æŒåŸå§‹å›¾åƒå¤§å°ï¼‰
        canvas = np.zeros_like(self.original_image)
        
        # è®¡ç®—ç²˜è´´ä½ç½®
        h, w = scaled_image.shape[:2]
        canvas_h, canvas_w = canvas.shape[:2]
        
        # åº”ç”¨åç§»é‡
        x_start = self.offset_x
        y_start = self.offset_y
        
        # è®¡ç®—æºå›¾åƒå’Œç›®æ ‡ç”»å¸ƒçš„æœ‰æ•ˆåŒºåŸŸ
        src_x1 = max(0, -x_start)
        src_y1 = max(0, -y_start)
        src_x2 = min(w, canvas_w - x_start)
        src_y2 = min(h, canvas_h - y_start)
        
        dst_x1 = max(0, x_start)
        dst_y1 = max(0, y_start)
        dst_x2 = min(canvas_w, x_start + w)
        dst_y2 = min(canvas_h, y_start + h)
        
        # ç²˜è´´å›¾åƒ
        if src_x2 > src_x1 and src_y2 > src_y1:
            canvas[dst_y1:dst_y2, dst_x1:dst_x2] = scaled_image[src_y1:src_y2, src_x1:src_x2]
        
        self.display_image = canvas
        cv2.imshow(self.window_name, self.display_image)
    
    def reset_view(self):
        """é‡ç½®è§†å›¾"""
        self.zoom_scale = 1.0
        self.offset_x = 0
        self.offset_y = 0
        self.update_display()


print("âœ“ æ­¥éª¤3å®Œæˆ: æ–‡ä»¶æŸ¥æ‰¾å’Œå›¾åƒæŸ¥çœ‹å™¨")
print("å·²æœ‰çŸ¥è¯†:")
print("  - find_image_annotation_pairs(): æŸ¥æ‰¾å›¾ç‰‡å’Œæ ‡æ³¨å¯¹")
print("  - ImageViewerç±»: æ”¯æŒé¼ æ ‡ç¼©æ”¾å’Œæ‹–æ‹½")
print("    Â· é¼ æ ‡æ»šè½®: ç¼©æ”¾")
print("    Â· é¼ æ ‡æ‹–æ‹½: å¹³ç§»")
print("    Â· reset_view(): é‡ç½®è§†å›¾")


def visualize_yolo_segment_dataset(folder_path, class_names=None, alpha=0.4, window_name='YOLO Segment Visualization'):
    """
    å¯è§†åŒ–YOLOåˆ†å‰²æ•°æ®é›†
    å‚æ•°:
        folder_path: åŒ…å«å›¾ç‰‡å’Œæ ‡æ³¨æ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„
        class_names: ç±»åˆ«åç§°å­—å…¸ {class_id: class_name}
        alpha: æ©ç é€æ˜åº¦ (0.0-1.0)
        window_name: çª—å£åç§°
    """
    # æŸ¥æ‰¾æ‰€æœ‰æˆå¯¹çš„å›¾ç‰‡å’Œæ ‡æ³¨
    pairs = find_image_annotation_pairs(folder_path)
    
    if not pairs:
        print(f"è­¦å‘Š: åœ¨ {folder_path} ä¸­æ²¡æœ‰æ‰¾åˆ°æˆå¯¹çš„å›¾ç‰‡å’Œæ ‡æ³¨æ–‡ä»¶")
        return
    
    print(f"æ‰¾åˆ° {len(pairs)} å¯¹å›¾ç‰‡å’Œæ ‡æ³¨æ–‡ä»¶")
    print(f"æ©ç é€æ˜åº¦: {alpha}")
    print("æ“ä½œè¯´æ˜:")
    print("  é¼ æ ‡æ»šè½®: æ”¾å¤§/ç¼©å°å›¾åƒ")
    print("  é¼ æ ‡å·¦é”®æ‹–æ‹½: ç§»åŠ¨å›¾åƒ")
    print("  æŒ‰ 'r': é‡ç½®è§†å›¾ï¼ˆæ¢å¤åŸå§‹å¤§å°å’Œä½ç½®ï¼‰")
    print("  æŒ‰ 'c' æˆ– ç©ºæ ¼é”®: åˆ‡æ¢åˆ°ä¸‹ä¸€å¼ å›¾ç‰‡")
    print("  æŒ‰ 'b': è¿”å›ä¸Šä¸€å¼ å›¾ç‰‡")
    print("  æŒ‰ 'q' æˆ– ESC: é€€å‡º")
    print("-" * 60)
    
    # åˆ›å»ºå›¾åƒæŸ¥çœ‹å™¨
    viewer = ImageViewer(window_name)
    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
    cv2.setMouseCallback(window_name, viewer.mouse_callback)
    
    current_idx = 0
    
    while True:
        img_path, txt_path = pairs[current_idx]
        
        # è¯»å–å›¾ç‰‡
        image = cv2.imread(img_path)
        if image is None:
            print(f"é”™è¯¯: æ— æ³•è¯»å–å›¾ç‰‡ {img_path}")
            current_idx = (current_idx + 1) % len(pairs)
            continue
        
        # è§£ææ ‡æ³¨
        annotations = parse_yolo_segment(txt_path)
        
        # åœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶åˆ†å‰²æ©ç 
        vis_image = image.copy()
        vis_image = draw_yolo_segment(vis_image, annotations, class_names, alpha)
        
        # æ ¹æ®å›¾åƒåˆ†è¾¨ç‡è‡ªé€‚åº”è°ƒæ•´ä¿¡æ¯æ å‚æ•°
        base_size = 1920
        scale_factor = min(vis_image.shape[1], vis_image.shape[0]) / base_size
        info_height = max(30, int(40 * scale_factor))
        info_font_scale = max(0.4, min(1.5, 0.7 * scale_factor))
        info_font_thickness = max(1, min(4, int(2 * scale_factor)))
        info_padding = max(5, int(10 * scale_factor))
        
        # æ·»åŠ å›¾ç‰‡ä¿¡æ¯
        img_name = os.path.basename(img_path)
        info_text = f"[{current_idx + 1}/{len(pairs)}] {img_name} - {len(annotations)} objects (alpha={alpha})"
        
        # åœ¨å›¾ç‰‡é¡¶éƒ¨æ·»åŠ ä¿¡æ¯æ 
        info_bar = np.zeros((info_height, vis_image.shape[1], 3), dtype=np.uint8)
        cv2.putText(
            info_bar,
            info_text,
            (info_padding, info_height - info_padding),
            cv2.FONT_HERSHEY_SIMPLEX,
            info_font_scale,
            (255, 255, 255),
            info_font_thickness
        )
        
        # å°†ä¿¡æ¯æ å’Œå›¾ç‰‡æ‹¼æ¥
        vis_image = np.vstack([info_bar, vis_image])
        
        # è‡ªåŠ¨è°ƒæ•´çª—å£å¤§å°ä»¥é€‚åº”å±å¹•
        screen_height = 1080  # å‡è®¾å±å¹•é«˜åº¦
        if vis_image.shape[0] > screen_height:
            initial_scale = screen_height / vis_image.shape[0]
            new_width = int(vis_image.shape[1] * initial_scale)
            new_height = int(vis_image.shape[0] * initial_scale)
            vis_image = cv2.resize(vis_image, (new_width, new_height))
        
        # è®¾ç½®å›¾åƒåˆ°æŸ¥çœ‹å™¨
        viewer.set_image(vis_image)
        
        # æ‰“å°å½“å‰å›¾ç‰‡ä¿¡æ¯
        print(f"[{current_idx + 1}/{len(pairs)}] {img_name} - {len(annotations)} ä¸ªç›®æ ‡")
        
        # ç­‰å¾…æŒ‰é”®
        while True:
            key = cv2.waitKey(10) & 0xFF
            
            if key == ord('q') or key == 27:  # 'q' æˆ– ESC é€€å‡º
                print("é€€å‡ºå¯è§†åŒ–")
                cv2.destroyAllWindows()
                return
            elif key == ord('c') or key == ord(' '):  # 'c' æˆ– ç©ºæ ¼ ä¸‹ä¸€å¼ 
                current_idx = (current_idx + 1) % len(pairs)
                break
            elif key == ord('b'):  # 'b' ä¸Šä¸€å¼ 
                current_idx = (current_idx - 1) % len(pairs)
                break
            elif key == ord('r'):  # 'r' é‡ç½®è§†å›¾
                viewer.reset_view()
                print("è§†å›¾å·²é‡ç½®")
    
    cv2.destroyAllWindows()


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description='YOLOåˆ†å‰²å¯è§†åŒ–å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # ä¸ä½¿ç”¨ç±»åˆ«åç§°ï¼ˆæ˜¾ç¤ºIDï¼‰
  python %(prog)s -i ./data/annotations
  
  # ä½¿ç”¨ç±»åˆ«åç§°æ–‡ä»¶
  python %(prog)s -i ./data/annotations -n classes.txt
  
  # è°ƒæ•´æ©ç é€æ˜åº¦
  python %(prog)s -i ./data/annotations -a 0.6

æ“ä½œè¯´æ˜:
  é¼ æ ‡æ»šè½®: æ”¾å¤§/ç¼©å°å›¾åƒ
  é¼ æ ‡å·¦é”®æ‹–æ‹½: ç§»åŠ¨å›¾åƒ
  æŒ‰ 'r': é‡ç½®è§†å›¾ï¼ˆæ¢å¤åŸå§‹å¤§å°å’Œä½ç½®ï¼‰
  æŒ‰ 'c' æˆ– ç©ºæ ¼é”®: åˆ‡æ¢åˆ°ä¸‹ä¸€å¼ å›¾ç‰‡
  æŒ‰ 'b': è¿”å›ä¸Šä¸€å¼ å›¾ç‰‡
  æŒ‰ 'q' æˆ– ESC: é€€å‡º

ç±»åˆ«åç§°æ–‡ä»¶æ ¼å¼ï¼ˆå¯é€‰ï¼‰:
  æ¯è¡Œæ ¼å¼: id name
  ä¾‹å¦‚:
    0 delivery
    1 box
    2 ExpressBillSeg
        """
    )
    
    parser.add_argument(
        '-i', '--input',
        type=str,
        default=r"D:/Project/yolo_train/Data/waybill_perception",
        help='è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„ï¼ŒåŒ…å«å›¾ç‰‡å’Œå¯¹åº”çš„txtåˆ†å‰²æ ‡æ³¨æ–‡ä»¶'
    )
    
    parser.add_argument(
        '-n', '--names',
        type=str,
        default=None,
        help='ç±»åˆ«åç§°æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰ï¼Œæ ¼å¼: æ¯è¡Œä¸º "id name"'
    )
    
    parser.add_argument(
        '-a', '--alpha',
        type=float,
        default=0.4,
        help='æ©ç é€æ˜åº¦ (0.0-1.0)ï¼Œé»˜è®¤0.4'
    )
    
    args = parser.parse_args()
    
    # éªŒè¯alphaå‚æ•°
    if not 0.0 <= args.alpha <= 1.0:
        print("é”™è¯¯: alphaå‚æ•°å¿…é¡»åœ¨0.0åˆ°1.0ä¹‹é—´")
        exit(1)
    
    # åŠ è½½ç±»åˆ«åç§°ï¼ˆå¦‚æœæä¾›ï¼‰
    class_names = None
    if args.names:
        class_names = load_class_names(args.names)
        if class_names:
            print(f"ç±»åˆ«åç§°: {len(class_names)} ä¸ªç±»åˆ«")
        else:
            print("æœªåŠ è½½ç±»åˆ«åç§°ï¼Œå°†æ˜¾ç¤ºæ•°å­—ID")
    else:
        print("æœªæŒ‡å®šç±»åˆ«åç§°æ–‡ä»¶ï¼Œå°†æ˜¾ç¤ºæ•°å­—ID")
    
    print(f"è¾“å…¥æ–‡ä»¶å¤¹: {args.input}")
    print("-" * 60)
    
    visualize_yolo_segment_dataset(args.input, class_names, args.alpha)


print("\n" + "=" * 60)
print("âœ“ æ­¥éª¤4å®Œæˆ: ä¸»å¯è§†åŒ–å‡½æ•°å’Œå‘½ä»¤è¡Œæ¥å£")
print("=" * 60)
print("\nğŸ“š å®Œæ•´çŸ¥è¯†æ€»ç»“:")
print("\n1. æ•°æ®ç»“æ„:")
print("   - YOLOåˆ†å‰²æ ¼å¼: class_id x1 y1 x2 y2 ... xn yn (å½’ä¸€åŒ–)")
print("   - è§£æç»“æœ: [(class_id, [(x1,y1), (x2,y2), ...]), ...]")
print("\n2. æ ¸å¿ƒå‡½æ•°:")
print("   - parse_yolo_segment(): è§£æåˆ†å‰²æ ‡æ³¨")
print("   - draw_yolo_segment(): ç»˜åˆ¶åŠé€æ˜æ©ç ")
print("   - visualize_yolo_segment_dataset(): ä¸»å¯è§†åŒ–å‡½æ•°")
print("\n3. å¯è§†åŒ–æŠ€æœ¯:")
print("   - cv2.fillPoly(): å¡«å……å¤šè¾¹å½¢æ©ç ")
print("   - cv2.polylines(): ç»˜åˆ¶å¤šè¾¹å½¢è¾¹ç•Œ")
print("   - cv2.addWeighted(): æ··åˆå®ç°åŠé€æ˜")
print("   - alphaå‚æ•°æ§åˆ¶é€æ˜åº¦")
print("\n4. äº¤äº’åŠŸèƒ½:")
print("   - é¼ æ ‡æ»šè½®ç¼©æ”¾")
print("   - é¼ æ ‡æ‹–æ‹½å¹³ç§»")
print("   - é”®ç›˜åˆ‡æ¢å›¾ç‰‡")
print("   - è‡ªé€‚åº”åˆ†è¾¨ç‡")
print("\n5. å‚æ•°:")
print("   - -i/--input: è¾“å…¥æ–‡ä»¶å¤¹")
print("   - -n/--names: ç±»åˆ«åç§°æ–‡ä»¶")
print("   - -a/--alpha: æ©ç é€æ˜åº¦ (0.0-1.0)")
print("\nâœ… YOLOåˆ†å‰²å¯è§†åŒ–å·¥å…·å¼€å‘å®Œæˆ!")
print("=" * 60)
